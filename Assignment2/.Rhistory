KevinDurant_FT <- c(209,209,391,452,756,594,431,679,703,146)
DerrickRose_FT <- c(146,146,146,197,259,476,194,0,27,152)
DwayneWade_FT <- c(629,432,354,590,534,494,235,308,189,284)
#Matrix
#
# <put your code here>
#
#Free Throw Attempts
KobeBryant_FTA <- c(819,768,742,564,541,583,451,626,21,241)
JoeJohnson_FTA <- c(330,314,379,362,269,243,186,161,195,176)
LeBronJames_FTA <- c(814,701,771,762,773,663,502,535,585,528)
CarmeloAnthony_FTA <- c(709,568,590,468,612,605,367,512,541,237)
DwightHoward_FTA <- c(598,666,897,849,816,916,572,721,638,271)
ChrisBosh_FTA <- c(581,590,559,617,590,471,279,302,272,232)
ChrisPaul_FTA <- c(465,357,390,524,190,384,302,323,345,321)
KevinDurant_FTA <- c(256,256,448,524,840,675,501,750,805,171)
DerrickRose_FTA <- c(205,205,205,250,338,555,239,0,32,187)
DwayneWade_FTA <- c(803,535,467,771,702,652,297,425,258,370)
#Matrix
#
# <put your code here>
#
#Matrix for Free Throws
#Bind the given vectors to form the matrix
FreeThrows <- rbind(KobeBryant_FT, JoeJohnson_FT, LeBronJames_FT, CarmeloAnthony_FT, DwightHoward_FT, ChrisBosh_FT, ChrisPaul_FT, KevinDurant_FT, DerrickRose_FT, DwayneWade_FT)
#Remove vectors - we don't need them anymore
remove(KobeBryant_FT, JoeJohnson_FT, CarmeloAnthony_FT, DwightHoward_FT, ChrisBosh_FT, LeBronJames_FT, ChrisPaul_FT, DerrickRose_FT, DwayneWade_FT, KevinDurant_FT)
FreeThrows
#Rename the columns
colnames(FreeThrows) <- Seasons
#Rename the rows
rownames(FreeThrows) <- Players
#Check the matrix
FreeThrows
#Matrix for Free Throw Attempts
#Bind the given vectors to form the matrix
FreeThrowAttempts <- rbind(KobeBryant_FTA, JoeJohnson_FTA, LeBronJames_FTA, CarmeloAnthony_FTA, DwightHoward_FTA, ChrisBosh_FTA, ChrisPaul_FTA, KevinDurant_FTA, DerrickRose_FTA, DwayneWade_FTA)
#Remove vectors - we don't need them anymore
remove(KobeBryant_FTA, JoeJohnson_FTA, CarmeloAnthony_FTA, DwightHoward_FTA, ChrisBosh_FTA, LeBronJames_FTA, ChrisPaul_FTA, DerrickRose_FTA, DwayneWade_FTA, KevinDurant_FTA)
#Rename the columns
colnames(FreeThrowAttempts) <- Seasons
#Rename the rows
rownames(FreeThrowAttempts) <- Players
#Check the matrix
FreeThrowAttempts
myplot <- function(z, who=1:10) {
matplot(t(z[who,,drop=F]), type="b", pch=15:18, col=c(1:4,6), main="Basketball Players Analysis")
legend("bottomleft", inset=0.01, legend=Players[who], col=c(1:4,6), pch=15:18, horiz=F)
}
#Visualize the new matrices
ggplot(FreeThrows)
install.packages(ggplot2)
install.packages(ggplot)
install.packages("ggplot2")
library(ggplot2)
#Visualize the new matrices
myplot(FreeThrows)
myplot(FreeThrowAttempts)
#Dear Student,
#
#Welcome to the dataset for the homework exercise.
#
#Instructions for this dataset:
# You have only been supplied vectors. You will need
# to create the matrices yourself.
# Matrices:
# - FreeThrows
# - FreeThrowAttempts
#
#Sincerely,
#Kirill Eremenko
#www.superdatascience.com
#Copyright: These datasets were prepared using publicly available data.
#           However, theses scripts are subject to Copyright Laws.
#           If you wish to use these R scripts outside of the R Programming Course
#           by Kirill Eremenko, you may do so by referencing www.superdatascience.com in your work.
#Comments:
#Seasons are labeled based on the first year in the season
#E.g. the 2012-2013 season is preseneted as simply 2012
#Notes and Corrections to the data:
#Kevin Durant: 2006 - College Data Used
#Kevin Durant: 2005 - Proxied With 2006 Data
#Derrick Rose: 2012 - Did Not Play
#Derrick Rose: 2007 - College Data Used
#Derrick Rose: 2006 - Proxied With 2007 Data
#Derrick Rose: 2005 - Proxied With 2007 Data
#Seasons
Seasons <- c("2005","2006","2007","2008","2009","2010","2011","2012","2013","2014")
#Players
Players <- c("KobeBryant","JoeJohnson","LeBronJames","CarmeloAnthony","DwightHoward","ChrisBosh","ChrisPaul","KevinDurant","DerrickRose","DwayneWade")
#Free Throws
KobeBryant_FT <- c(696,667,623,483,439,483,381,525,18,196)
JoeJohnson_FT <- c(261,235,316,299,220,195,158,132,159,141)
LeBronJames_FT <- c(601,489,549,594,593,503,387,403,439,375)
CarmeloAnthony_FT <- c(573,459,464,371,508,507,295,425,459,189)
DwightHoward_FT <- c(356,390,529,504,483,546,281,355,349,143)
ChrisBosh_FT <- c(474,463,472,504,470,384,229,241,223,179)
ChrisPaul_FT <- c(394,292,332,455,161,337,260,286,295,289)
KevinDurant_FT <- c(209,209,391,452,756,594,431,679,703,146)
DerrickRose_FT <- c(146,146,146,197,259,476,194,0,27,152)
DwayneWade_FT <- c(629,432,354,590,534,494,235,308,189,284)
#Matrix
#
# <put your code here>
#
#Free Throw Attempts
KobeBryant_FTA <- c(819,768,742,564,541,583,451,626,21,241)
JoeJohnson_FTA <- c(330,314,379,362,269,243,186,161,195,176)
LeBronJames_FTA <- c(814,701,771,762,773,663,502,535,585,528)
CarmeloAnthony_FTA <- c(709,568,590,468,612,605,367,512,541,237)
DwightHoward_FTA <- c(598,666,897,849,816,916,572,721,638,271)
ChrisBosh_FTA <- c(581,590,559,617,590,471,279,302,272,232)
ChrisPaul_FTA <- c(465,357,390,524,190,384,302,323,345,321)
KevinDurant_FTA <- c(256,256,448,524,840,675,501,750,805,171)
DerrickRose_FTA <- c(205,205,205,250,338,555,239,0,32,187)
DwayneWade_FTA <- c(803,535,467,771,702,652,297,425,258,370)
#Matrix
#
# <put your code here>
#
#Part 1 - Free Throw Attempts Per Game
#(You will need the Games matrix)
myplot(FreeThrows/Games)
#Part 2 - Free Throw Accuracy
myplot(FreeThrows/FreeThrowAttempts)
x <- 6
y <- 4
z <- x + y
z
# More commonly a function will operate on an object
sqrt(16)
# Remove objects from current workspace with rm function:
rm(x,y)
x <- c(5,9)
y <- c(1,0)
z <- c(x,y)
# OR using the sequence function which allows steps
seq(1,9, by=2)
# Sequence can be generated by:
a <- 1:10
# Repeat Function
rep(0,100)
rep(1:3,6)
# Another variation for repeat
rep(1:3,c(6,6,6))
x <- c(6,8,9)
y <- c(1,2,4)
x + y
x <- c(4,2,6)
y <- c(1,0,-1)
length(x)
sum(x)
sum(x^2)
x + y
x * y
x-2
x ^ 2
7:11
seq(2,9)
seq(4,10,by=2)
seq(3,30,length=10)
seq(6,-4,by=-2)
rep(2,4)
rep(c(1,2),4)
rep(c(1,2),c(4,4))
rep(1:4,4)
rep(1:4, rep(3,4))
rep(6,6)
rep(c(5,8),4)
rep(c(5,8),c(4,4))
x<-c(7.5,8.2,3.1,5.6,8.2,9.3,6.5,7.0,9.3,1.2,14.5,6.2)
# Simple Summary of the data
mean(x)
var(x)
summary(x)
summary(x[1:6])
summary(x[7:12])
# Matrices
x <- c(5,7,9)
y <- c(6,3,4)
z <- cbind(x,y)
z
dim(z)
rbind(z,z)
# Matrices can also be build by explicit construction
z <- matrix(c(5,7,9,6,3,4), nrow=3)
z
y <- matrix(c(1,3,0,9,5,-1), nrow=3, byrow=T)
y
# We obtain
y  z
# We obtain
y + z
z
# Matrices can also be build by explicit construction
z <- matrix(c(5,7,9,6,3,4), nrow=3, byrow=T)
z
y <- matrix(c(1,3,0,9,5,-1), nrow=3, byrow=T)
y
# We obtain
y + z
y * z
x <- matrix(c(3,4,-2,6), nrow=2, byrow=T)
x
y%*%x
# Matrix Transpose t() and solve to calculate inverse
t(z)
solve(x)
x <- matrix(c(3,2,-1,1) nrow=2, byrow=T)
x <- matrix(c(3,2,-1,1), nrow=2, byrow=T)
x
y <- matrix(c(1,4,0,0,1,-1), nrow=2, byrow=T)
y
2*x
x*x
x%*%x
x%*%y
t(y)
solve(x)
x[1,]
x[2,]
x[,2]
y[1,2]
y[,2:3]
trees[1:5,]
head(trees)
attach(trees)
mean(Height)
mean(trees[,2])
#Exercise
attach(quakes)
summary(depth)
summary(mag)
attach(mtcars)
help(mtcars)
mean(wt)
## Apply function
apply(trees,2,mean)
apply(mtcars,2,mean)
apply(quakes,2,mean)
y <- matrix(c(1,4,1,0,2,-1), nrow=2, byrow=T)
y
apply(y[,2:3],1,mean)
# Statistical Computation and Simulation
# For example X ~ N(3,2^2)
dnorm(5,3,2)
# Graphics
# Dividing a page into smaller pieces
par(mfrow=c(2,2))
hist(Height)
boxplot(Height)
hist(Volume)
boxplot(Volume)
par(mforw=c(1,1))
par(mfrow=c(2,2))
hist(Height)
boxplot(Height)
hist(Volume)
boxplot(Volume)
par(mforw=c(1,1))
par(mfrow=c(2,2))
hist(Height)
boxplot(Height)
hist(Volume)
boxplot(Volume)
par(mfrow=c(1,1))
#Examples
plot(Height, Volume)
pairs(trees)
data("nhtemp")
plot(nhtemp)
plot(faithful)
data("HairEyeColor")
plot(HairEyeColor)
# Example
x <- c(9,5,2,3,7)
# Writing Functions
# Defining functions
sd <- function(x) sqrt(var(x))
sd(x)
# Multiple lines
fix(several.plots)
several.plots(faithful)
carData <- as.data.frame(cars)
carData <- as.data.frame(cars)
head(carData)
# calculate the time taken
carData$time <- dist/speed
# calculate the time taken
carData$time <- carData$dist/carData$speed
head(carData)
# Basic Exploration
dim(carData)
names(carData)
str(carData)
help(car)
help(??car)
help(cars)
cor([,0:2])
cor(carData[,0:2])
help(cars)
# Plotting
plot(cars, xlab = "Speed (mph)", ylab = "Stopping distance (ft)",
las = 1)
lmfit <- lm(speed~dist, data = carData)
lmfit$coefficients
abline(lmfit$coefficients, col="red", lwd=4)     # draw the optimal regression line
lmfit <- lm(dist~speed, data = carData)
lmfit$coefficients
abline(lmfit$coefficients, col="red", lwd=4)     # draw the optimal regression line
plot(cars, xlab = "Speed (mph)", ylab = "Stopping distance (ft)",
las = 1)
lmfit <- lm(dist~speed, data = carData)
lmfit$coefficients
abline(lmfit$coefficients, col="red", lwd=4)
lmfit$residuals
sum(lmfit$residuals^2)
#random guess
mean(carData$dist)
sum((carData$dist - mean(carData$dist))^2) # SSE
sse <- sum((carData$dist - mean(carData$dist))^2) # SSE
sd = sqrt(sse)
sd
sse <- sum((carData$dist - mean(carData$dist))^2) # SSE
sse
summary(lmfit)
help(lm)
# Note that R comes with a bunch of inbuilt datasets
data()
# ---------------------------------------------------------
# Task 1 : Assign the dataset to a variable
cars_dataset <- data(cars)
# 2a : dimension of the dataset
dim(cars_dataset)
# ---------------------------------------------------------
# Task 1 : Assign the dataset to a variable
cars_dataset <- as.data.frame(cars)
# 2a : dimension of the dataset
dim(cars_dataset)
# 2b : labels of the columns/variables
names(cars_dataset)
# 2c : structure of the dataset
str(cars_dataset)
# 2d : first few rows of the data
head(cars_dataset)
# 2e : last few rows of the data
tail(cars_dataset)
# 2f : summary statistics for all variables
summary(cars_dataset)
# 3a : histograms of speed and dist
hist(cars_dataset$speed, cars_dataset$dist)
# 3a : histograms of speed and dist
hist(cars_dataset$speed)
# 3b : histograms of speed and dist
hist(cars_dataset$dist)
# ---------------------------------------------------------
# Task 4 : Find the correlation between "speed" and "dist"
cor(cars_dataset$speed, cars_dataset$dist)
# ---------------------------------------------------------
# Task 5 : Plot speed vs dist in a 2d scatterplot (points)
points(cars_dataset$speed, cars_dataset$dist)
# ---------------------------------------------------------
# Task 5 : Plot speed vs dist in a 2d scatterplot (points)
points(cars_dataset$speed, cars_dataset$dist)
# ---------------------------------------------------------
# Task 5 : Plot speed vs dist in a 2d scatterplot (points)
e <- ggplot(cars_dataset, aes(speed, dist))
# ---------------------------------------------------------
# Task 5 : Plot speed vs dist in a 2d scatterplot (points)
points(cars_dataset$speed, cars_dataset$dist)
# ---------------------------------------------------------
# Task 5 : Plot speed vs dist in a 2d scatterplot (points)
help(points)
points(x=cars_dataset$speed, y=cars_dataset$dist, type="p")
plot.new
clear
# ---------------------------------------------------------
# Task 1 : Assign the dataset to a variable
cars_dataset <- as.data.frame(cars)
# 2a : dimension of the dataset
dim(cars_dataset)
# 2b : labels of the columns/variables
names(cars_dataset)
# 2c : structure of the dataset
str(cars_dataset)
# 2d : first few rows of the data
head(cars_dataset)
# 2e : last few rows of the data
tail(cars_dataset)
# 2f : summary statistics for all variables
summary(cars_dataset)
# 3a : histograms of speed and dist
hist(cars_dataset$speed)
# 3b : histograms of speed and dist
hist(cars_dataset$dist)
points(x=cars_dataset$speed, y=cars_dataset$dist, type="p")
plot(x=cars_dataset$speed, y=cars_dataset$dist, type="p")
# 6a : fit a linear model on dist vs speed in the data
lm.fit(x=cars_dataset$dist, y=cars_dataset$speed)
# 6a : fit a linear model on dist vs speed in the data
lmfit <- lm(dist~speed, data = cars_dataset)
# 6b : find the coefficients of the linear model
lmfit$coefficients
# 6c : plot the regression line on the scatterplot
abline(lmfit$coefficients, col="red", lwd=4)
# 7b : find the final "residual sum of squares" of errors
lmfit$residuals
sum(lmfit$residuals^2)
sum(lmfit$residuals^2)
# 7a : find the initial "total sum of squares" of errors
lmfit
# 7c : by how much did you "improve" the sum of squares
lmfit$effects
?boxplot()
boxplot(cars_dataset$speed)
# ---------------------------------------------------------
# Task 1 : Assign the dataset to a variable
cars_dataset <- as.data.frame(cars)
boxplot(cars_dataset$speed)
boxplot(cars_dataset$speed, horizontal = TRUE)
# 7a : find the initial "total sum of squares" of errors
TSS <- sum((carData$dist - mean(carData$dist))^2)
TSS
# 7b : find the final "residual sum of squares" of errors
lmfit$residuals
sum(lmfit$residuals^2)
# 7c : by how much did you "improve" the sum of squares
TSS - RSS
RSS <- sum(lmfit$residuals^2)
# 7c : by how much did you "improve" the sum of squares
TSS - RSS
# We have improved the 21185.46 in terms of sum of squares.
# Proportionally
(TSS-RSS)/TSS
summary(lmfit)
setwd("~/Desktop/ntu-ay-2018s1/CE4073 - Data Science For Business/Assignment2")
# Read CSV
churn_dataset <- read.csv('assign2_ChurnData.csv')
# EDA
str(churn_dataset)
head(churn_dataset)
head(churn_dataset)
summary(churn_dataset)
# Converting to data frame for easier data processing
adm_churn <- as.data.frame(churn_dataset)
# Remove Null Values From the DataFrame
adm_churn <- na.omit(adm_churn)
# Create a sample training data using 70% of the data frame and saving it as
# train data
train <- sample(nrow(adm_churn), 0.7*nrow(adm_churn), replace = FALSE)
adm_Train <- adm_churn[train,]
adm_Valid <- adm_churn[-train,]
# Summary of Train and Test Data
summary(adm_Train)
summary(adm_Valid)
library("rpart")
tree <- rpart(Churn ~. , method='class', data=adm_Train)
printcp(tree)
library(rpart.plot)
prp(tree)
predTrain <- predict(tree, adm_Train, type = "class")  # prediction on train set
mean(predTrain == adm_Train$Churn)                     # classification accuracy
predValid <- predict(tree, adm_Valid, type = "class")  # prediction on validation set
mean(predValid == adm_Valid$Churn)
library(randomForest)
rf.model <- randomForest(Churn ~., data=adm_Train)
print(rf.model)
rf.model$predicted
library(randomForest)
rf.model <- randomForest(Churn ~., data=adm_Train, ntree=2000)
print(rf.model)
rf.model$predicted
print(rf.model)
(2281 + 483) / (2281 + 279 + 450 + 483)
Prediction <- predict(fit, adm_Valid)
Prediction <- predict(rf.model, adm_Valid)
submit <- data.frame(Churn = Prediction)
write.csv(submit, file = "churn_prediction.csv", row.names = FALSE)
titanic_train <- read.csv("titanic_train.csv")
titanic_test <- read.csv("titanic_test.csv")
head(titanic_train)
# EDA
summary(titanic_train)
Agefit <- rpart(Age ~ Pclass + Sex + SibSp + Parch + Fare,
data=titanic_train[!is.na(titanic_train$Age),],
method="anova")
titanic_train$Age[is.na(titanic_train$Age)] <- predict(Agefit, titanic_train[is.na(titanic_train$Age),])
AgefitTest <- rpart(Age ~ Pclass + Sex + SibSp + Parch + Fare,
data=titanic_test[!is.na(titanic_test$Age),],
method="anova")
titanic_test$Age[is.na(titanic_test$Age)] <- predict(AgefitTest, titanic_test[is.na(titanic_test$Age),])
which(is.na(titanic_test$Fare))
titanic_test$Fare[153] <- mean(titanic_test$Fare, na.rm = T)
which(is.na(titanic_test$Fare))
titanic_test$Fare[153] <- mean(titanic_test$Fare, na.rm = T)
library("rpart")
titanic_tree <- rpart(Survived ~Pclass + Sex + Age + SibSp + Parch + Fare, method='class', data=titanic_train)
printcp(titanic_tree)
# Display the nicer tree plot
prp(titanic_tree)
predTrain <- predict(titanic_tree, titanic_train, type = "class")  # prediction on train set
mean(predTrain == titanic_train$Survived)                     # classification accuracy
predTest <- predict(titanic_tree, titanic_test, type="class") # prediction on test set
print(predTest) # classification accuracy
Prediction <- predict(fit, titanic_test)
# Build the randomForest model !
fit <- randomForest(Survived ~ Pclass + Sex + Age + SibSp + Parch + Fare , method='class', data=titanic_train, ntree=2000)
Prediction <- predict(fit, titanic_test)
submit <- data.frame(PassengerId = titanic_test$PassengerId, Survived = Prediction)
# Save it into a csv file in case professor is uploading to Kaggle
write.csv(submit, file = "firstforest.csv", row.names = FALSE)
Prediction
